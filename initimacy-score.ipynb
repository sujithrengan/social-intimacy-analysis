{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhUqlJbR6x7s","executionInfo":{"status":"ok","timestamp":1669827009158,"user_tz":360,"elapsed":22320,"user":{"displayName":"Kunal Vudathu","userId":"05018577979584034672"}},"outputId":"077eef23-db38-4184-c26d-972e146f7558"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/Shareddrives/'CSCE 638 NLP'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOynzc1S66bC","executionInfo":{"status":"ok","timestamp":1669827009158,"user_tz":360,"elapsed":6,"user":{"displayName":"Kunal Vudathu","userId":"05018577979584034672"}},"outputId":"8b70f7bf-d0f8-44d0-810f-9063321c02a6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/Shareddrives/CSCE 638 NLP\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLC9zYeS7GSc","executionInfo":{"status":"ok","timestamp":1669827009938,"user_tz":360,"elapsed":784,"user":{"displayName":"Kunal Vudathu","userId":"05018577979584034672"}},"outputId":"e9c916f7-818a-4d12-ea20-715958019914"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["'9_10_2022_Who Will R.pdf'\n"," all_data\n"," all_question_data.zip\n"," annotated_question_intimacy_data\n"," explained.html\n"," Extra_dataset\n"," Gender_detection.ipynb\n"," gender_predictor.pkl\n"," gender_predictor_v2.pkl\n","'NLP Project_initimacy_score.ipynb'\n","'NLP Project_kunal.ipynb'\n"," NLP_project_visualization.ipynb\n"," outputs\n"," outputs_question_initmacy_semeval\n","'Project Abstract.gdoc'\n","'Project - Social intimacy'\n","'Sujith_Deberta-NLP Project_template.ipynb'\n"," test_output\n"," test_prediction_final.txt\n","'Topic detection.ipynb'\n"," train_all.txt\n"," train.csv\n"," train.gsheet\n"," train.txt\n"]}]},{"cell_type":"markdown","source":["### Install Dependencies"],"metadata":{"id":"goagyNsjz2Nq"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbVR7Ina42F3","outputId":"8c1709be-a48d-40ed-da77-3159ca720d4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 42.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 41.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.24.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n"]}]},{"cell_type":"code","source":["import torch\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"id":"ZfLdWkp171cM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define args here such as model to use and path to dataset"],"metadata":{"id":"AaaD25dnz5jL"}},{"cell_type":"code","source":["class Args:\n","\n","  model_name = 'pedropei/question-intimacy'\n","  pre_trained_model_name_or_path = 'pedropei/question-intimacy'\n","  train_path = \"./all_data/train_train.txt\"\n","  val_path = \"./all_data/train_validate.txt\"\n","  test_path = \"./all_data/train_test.txt\"\n","  model_saving_path = \"./outputs\"\n","  test_saving_path = \"./test_output/test.txt\"\n","\n","\n","  # prior work dataset\n","  # model_name = 'roberta-base'\n","  # pre_trained_model_name_or_path = 'roberta-base'\n","  # train_path=data/annotated_question_intimacy_data/final_train.txt \\\n","  # val_path=data/annotated_question_intimacy_data/final_val.txt \\\n","  # test_path=data/annotated_question_intimacy_data/final_test.txt \\\n","  # model_saving_path = \"./outputs\"\n","  # test_saving_path = \"./test_output/test.txt\"\n","\n","def arguments():\n","    parser = ArgumentParser()\n","    parser.set_defaults(show_path=False, show_similarity=False)\n","\n","    parser.add_argument('--model_name')\n","    parser.add_argument('--pre_trained_model_name_or_path')\n","    parser.add_argument('--train_path', default='train.txt')\n","    parser.add_argument('--val_path', default='val.txt')\n","    parser.add_argument('--test_path', default='test.txt')\n","    parser.add_argument('--model_saving_path', default=None)\n","    parser.add_argument('--test_saving_path', default=None)\n","\n","    return parser.parse_args()\n"],"metadata":{"id":"HAuAtRdQ53B_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Set Hyperparameters"],"metadata":{"id":"fnqy-U0C2ODK"}},{"cell_type":"code","source":["class Config(object):\n","\tdef __init__(self, model_name=None):\n","\t\tself.model_name = model_name\n","\t\tself.max_epochs = 50\n","\t\tself.lr = 0.0001\n","\t\tself.batch_size = 128\n","\t\tself.cuda = True\n","\t\tself.max_len = 50\n","\t\tself.warmup_ratio = 0.06\n","\t\tself.weight_decay=0.0\n","\t\tself.gradient_accumulation_steps = 1\n","\t\tself.adam_epsilon = 1e-08"],"metadata":{"id":"nPZSjG9q4AVd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset preprocessing"],"metadata":{"id":"vfQFr-6nqBRy"}},{"cell_type":"code","source":["'''\n","Convert csv to txt\n","'''\n","def convert():\n","  import csv\n","  import random\n","  csv_file = 'train.csv' # 'Extra_dataset/reddit_post_questions.csv'\n","  out_file = 'train.txt' # 'Extra_dataset/reddit_post_questions.txt'\n","  with open(out_file, \"w\") as f_out:\n","      with open(csv_file, \"r\") as f_in:\n","        fr = csv.reader(f_in)\n","        next(fr)\n","        for row in fr:\n","          txt, score = row[0], float(row[1])\n","          # txt, score = row[1], float(row[2])\n","          # score = 1 + 4*((score+1)/2) # convert from [-1, 1] to [1, 5]\n","          if row[2]=='English':\n","            f_out.write(txt+\" \"+ str(score) + '\\n')\n","      f_out.close()\n","\n","'''\n","Merging different datasets\n","'''\n","def combine():\n","  input_files = ['train.txt','reddit.txt','movie.txt','question.txt']\n","  output_file = 'train_all.txt'\n","\n","  with open(output_file, 'w') as outfile:\n","      for names in input_files:\n","          with open(names) as infile:\n","              outfile.write(infile.read())\n","          outfile.write(\"\\n\")\n","\n","'''\n","Shuffling the data\n","'''\n","def shuffle():\n","  input_file = 'train_all.txt'\n","  output_file = 'train_shuffled.txt'\n","\n","  lines = open(input_file).readlines()\n","  random.shuffle(lines)\n","  open(output_file, 'w').writelines(lines)\n","\n","'''\n","Splitting the data into train, test and validate datasets\n","80-10-10 split\n","'''\n","def split():\n","  train = 0\n","  validate = 0\n","\n","  input_file = 'train_shuffled.txt'\n","  train_output_file = 'all_train.txt'\n","  validate_output_file = 'all_validate.txt'\n","  test_output_file = 'all_test.txt'\n","\n","  with open(input_file, 'r') as file:\n","      lines = file.readlines()\n","      train = int(0.8*len(lines))\n","      validate = int(0.9*len(lines))\n","\n","  with open(train_output_file, 'w') as file:\n","      for line in lines[:train]:\n","          file.write(line)\n","\n","  with open(validate_output_file, 'w') as file:\n","      for line in lines[train:validate]:\n","          file.write(line)\n","\n","  with open(test_output_file, 'w') as file:\n","      for line in lines[validate:]:\n","          file.write(line)\n"],"metadata":{"id":"dn7ZWT8-hVSg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_data(path):\n","    print('open:',path)\n","    text = []\n","    y = []\n","    with open(path, 'r') as r:\n","        lines = r.readlines()\n","        for line in lines:\n","            line = line.strip('\\n').split(' ')\n","            try:\n","              # y.append(float(line[-1]))\n","              y.append(((float(line[-1])/2)-1.5))\n","            except Exception as e:\n","              # print(line)\n","              print(\"Error parsing line: \", line)\n","              continue\n","            text.append(' '.join(line[:-1]))\n","    return text,y"],"metadata":{"id":"aSZVlRfcsggr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Helper functions to run epochs"],"metadata":{"id":"BZkFeMe_2UEl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6n-FdY1AZ6OU"},"outputs":[],"source":["# train.py\n","\n","import math\n","from scipy import stats\n","import numpy as np\n","from tqdm import tqdm\n","import torch.optim as optim\n","from torch import nn, Tensor\n","from torch.autograd import Variable\n","import torch\n","from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel, RobertaForSequenceClassification, XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaForSequenceClassification, XLNetModel, XLNetTokenizer, XLNetForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n","from argparse import ArgumentParser\n","\n","\n","torch.manual_seed(0)\n","\n","\n","def padding(text, pad, max_len = 50):\n","\n","    return text if len(text) >= max_len else (text + [pad] * (max_len-len(text)))\n","\n","def encode_batch(text, berts, max_len = 50):\n","    tokenizer = berts[0]\n","    t1 = []\n","    for line in text:\n","        t1.append(padding(tokenizer.encode(line,add_special_tokens = True, max_length = max_len,truncation=True),tokenizer.pad_token_id,max_len))\n","    return t1\n","\n","\n","def data_iterator(train_x, train_y, batch_size = 64):\n","    n_batches = math.ceil(len(train_x) / batch_size)\n","    for idx in range(n_batches):\n","        x = train_x[idx *batch_size:(idx+1) * batch_size]\n","        y = train_y[idx *batch_size:(idx+1) * batch_size]\n","        yield x, y\n","\n","def run_epoch(model, train_data, val_data, tokenizer,config, optimizer):\n","    train_x, train_y = train_data[0], train_data[1]\n","    val_x, val_y = val_data[0], val_data[1]\n","    iterator = data_iterator(train_x, train_y, config.batch_size)\n","    train_losses = []\n","    val_accuracies = []\n","    losses = []\n","\n","    for i, (x,y) in tqdm(enumerate(iterator),total=int(len(train_x)/config.batch_size)):\n","        #print('iteration', i) \n","        model.zero_grad()\n","\n","        ids = encode_batch(x, (tokenizer,model), max_len = config.max_len)\n","\n","\n","        if config.cuda:\n","            input_ids = Tensor(ids).cuda().long()\n","            labels = torch.cuda.FloatTensor(y)\n","        else:\n","            input_ids = Tensor(ids).long()\n","            labels = torch.FloatTensor(y)\n","\n","        outputs = model(input_ids, labels=labels)\n","        loss, logits = outputs[:2]\n","\n","        loss.backward()\n","        #print('train_loss',loss)\n","        losses.append(loss.data.cpu().numpy())\n","        optimizer.step()\n","\n","        if (i + 1) % 1 == 0:\n","            #print(\"Iter: {}\".format(i))\n","            avg_train_loss = np.mean(losses)\n","            train_losses.append(avg_train_loss)\n","            #print(\"\\tAverage training loss: {:.5f}\".format(avg_train_loss))\n","            losses = []\n","\n","            # Evalute Accuracy on validation set\n","            model.eval()\n","            all_preds = []\n","            val_iterator = data_iterator(val_x, val_y, config.batch_size)\n","            for x, y in val_iterator:\n","                ids = encode_batch(x, (tokenizer,model), max_len = config.max_len)\n","                #x = Variable(Tensor(x))\n","\n","                with torch.no_grad():\n","\n","                    if config.cuda:\n","                        input_ids = Tensor(ids).cuda().long()\n","                        labels = torch.cuda.FloatTensor(y)\n","                    else:\n","                        input_ids = Tensor(ids).long()\n","                        labels = torch.FloatTensor(y)\n","                    outputs = model(input_ids, labels=labels)\n","                    loss, y_pred = outputs[:2]\n","\n","                predicted = y_pred.cpu().data\n","\n","                all_preds.extend(predicted.numpy())\n","\n","            \n","            all_res = np.array(all_preds).flatten()            \n","            score = (np.square(val_y - all_res)).mean()\n","            val_accuracies.append(score)\n","            model.train()\n","\n","    return train_losses, val_accuracies\n","\n","def get_test_result(model, test_x, test_y, config,tokenizer, save_path, ext_test = False, pure_inference=False):\n","    cuda = config.cuda\n","    all_raw = []\n","    all_preds = []\n","    all_y = []\n","    all_x = []\n","    test_iterator = data_iterator(test_x, test_y, batch_size=256)\n","    model.eval()\n","    i = 0\n","    for x, y in test_iterator:\n","        print(str(i * 256) + '/' + str(len(test_x)))\n","        i += 1\n","        #print(x[:5])\n","        ids = encode_batch(x, (tokenizer, model), max_len = config.max_len)\n","        # x = Variable(Tensor(x))\n","\n","        with torch.no_grad():\n","            if cuda:\n","                input_ids = Tensor(ids).cuda().long()\n","                #labels = torch.cuda.FloatTensor(y)\n","            else:\n","                input_ids = Tensor(ids).long()\n","                #labels = torch.FloatTensor(y)\n","            outputs = model(input_ids)\n","            y_pred = outputs[0]\n","\n","        predicted = y_pred.cpu().data\n","        #predicted = torch.max(y_pred.cpu().data, 1)[1]\n","        all_preds.extend(predicted.numpy())\n","        #all_raw.extend(y_pred.cpu().data.numpy())\n","        all_y.extend(y)\n","        all_x.extend(x)\n","\n","\n","    #all_res = [1 if i[0] > 0 else -1 for i in all_preds]\n","    all_res = np.array(all_preds).flatten()\n","    #all_raw = np.array(all_raw)\n","\n","    if save_path:\n","        with open(save_path, 'w') as w:\n","            if pure_inference:\n","                 for i in range(len(all_y)):                \n","                    if i < 2:\n","                        print(all_x[i], all_res[i])                    \n","                    w.writelines(all_x[i] + '\\t' + str(all_res[i]) + '\\n')\n","            else:\n","                for i in range(len(all_y)):                \n","                    if i < 2:\n","                        print(all_x[i], all_res[i], test_y[i])                    \n","                    w.writelines(all_x[i] + '\\t' + str(all_y[i]) + '\\t' + str(all_res[i]) + '\\n')\n","    \n","    if not pure_inference:\n","        print('mse:', (np.square(all_y - all_res)).mean())\n","        print('pearson r:', stats.pearsonr(all_res, all_y)[0])\n","\n","    if ext_test:\n","        print('book pearson r:', stats.pearsonr(all_res[:50], all_y[:50])[0])\n","        print('twitter pearson r:', stats.pearsonr(all_res[50:100], all_y[50:100])[0])\n","        print('movie pearson r:', stats.pearsonr(all_res[100:150], all_y[100:150])[0])\n","\n","    return all_res, all_y\n","\n","\n"]},{"cell_type":"markdown","source":["Helper function to determine Pearson R and MSE"],"metadata":{"id":"4Vlv86Ya2ZZK"}},{"cell_type":"code","source":["def get_metrics(model, test_x, test_y, config, tokenizer, test = False, save_path='test_prediction_final.txt'):\n","    cuda = config.cuda\n","    all_preds = []\n","    test_iterator = data_iterator(test_x, test_y, batch_size=64)\n","    all_y = []\n","    all_x = []\n","    model.eval()\n","    for x, y in test_iterator:\n","        ids = encode_batch(x, (tokenizer,model), max_len = config.max_len)\n","        with torch.no_grad():\n","            if cuda:\n","                input_ids = Tensor(ids).cuda().long()                \n","                labels = torch.cuda.FloatTensor(y)\n","            else:\n","                input_ids = Tensor(ids).long()\n","                labels = torch.FloatTensor(y)\n","            outputs = model(input_ids, labels=labels)\n","            loss, y_pred = outputs[:2]\n","\n","        predicted = y_pred.cpu().data\n","        all_preds.extend(predicted.numpy())\n","        all_y.extend(y)\n","        all_x.extend(x)\n","\n","    all_res = np.array(all_preds).flatten()\n","    if test and save_path:\n","        with open(save_path, 'w') as w:\n","            for i in range(len(all_y)):\n","                if i < 2:\n","                    print(all_x[i], all_res[i], test_y[i])\n","                w.writelines(all_x[i] + '\\t' + str(all_y[i]) + '\\t' + str(all_res[i]) + '\\n')\n","\n","    #print('pearson r:', stats.pearsonr(all_res, all_y)[0])\n","    score = 0\n","    return loss,stats.pearsonr(all_res, all_y)[0]"],"metadata":{"id":"3j167lyLhhtp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper functions for visualizations\n"],"metadata":{"id":"NQSTm5Q62e_d"}},{"cell_type":"code","source":["import matplotlib\n","import matplotlib.colors as colors\n","from IPython.core.display import display, HTML\n","\n","def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n","    new_cmap = colors.LinearSegmentedColormap.from_list(\n","        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n","        cmap(np.linspace(minval, maxval, n)))\n","    return new_cmap\n","\n","def colorize(inputs, color_arrays):\n","    cmap = truncate_colormap(matplotlib.cm.YlOrRd, maxval=0.9)\n","    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n","    colored_string = ''\n","    for words, color_array in zip(inputs, color_arrays):\n","        for i, (word, color) in enumerate(zip(words.split(), color_array)):\n","            # print(word, color)\n","            color = matplotlib.colors.rgb2hex(cmap(color)[:3])\n","            colored_string += template.format(color, '&nbsp' + word + '&nbsp')\n","            if not (i+1)%25:\n","                colored_string += '<br>'\n","        # colored_string += '<p>next tweet</p>'\n","        colored_string += '<br>'\n","\n","    with open('explained.html', 'w') as f:\n","       f.write(colored_string)\n","    display(filename='explain.html')"],"metadata":{"id":"BQIz3d-nq09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main function"],"metadata":{"id":"gM6UoWib2k8I"}},{"cell_type":"code","source":["args = Args()\n","config = Config(args.model_name)\n","# Change tokenizer import and model import when trying different model\n","tokenizer = XLNetTokenizer.from_pretrained(args.pre_trained_model_name_or_path, num_labels=1, output_attentions = False,output_hidden_states = False)\n","# tokenizer = RobertaTokenizer.from_pretrained(args.pre_trained_model_name_or_path, num_labels=1, output_attentions = False,output_hidden_states = False)\n","# tokenizer = AutoTokenizer.from_pretrained(args.pre_trained_model_name_or_path, num_labels=1, output_attentions = False,output_hidden_states = False)\n","# tokenizer = XLMRobertaTokenizer.from_pretrained(args.pre_trained_model_name_or_path, num_labels=1, output_attentions = False,output_hidden_states = False)\n","# Create Model with specified optimizer and loss function\n","##############################################################\n","\n","# model = AutoModelForSequenceClassification.from_pretrained(args.pre_trained_model_name_or_path,num_labels=1,output_attentions = False,output_hidden_states = False)\n","# model = XLMRobertaForSequenceClassification.from_pretrained(args.pre_trained_model_name_or_path,num_labels=1,output_attentions = False,output_hidden_states = False)\n","model = XLNetForSequenceClassification.from_pretrained(args.pre_trained_model_name_or_path,num_labels=1,output_attentions = False,output_hidden_states = False)\n","if config.cuda:\n","    model.cuda()\n","      \n","          \n","train_text,  train_labels = get_data(args.train_path)\n","val_text,  val_labels = get_data(args.val_path)\n","test_text,  test_labels = get_data(args.test_path)\n","# print(\"text: \", test_text[:5])\n","# print(\"labels:\", test_labels[:5])\n","# print(len(test_text), \"---\", len(test_labels))\n","\n","train_x = train_text\n","train_y = np.array(train_labels)\n","val_x = val_text\n","val_y = np.array(val_labels)\n","model.train()\n","optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=1e-6)\n","##############################################################\n","\n","train_data = [train_x, train_y]\n","val_data = [val_x, val_y]\n","\n","# Get Accuracy of final model\n","test_x = test_text\n","test_y = np.array(test_labels)\n","best_val = 100.0\n","best_test = 100.0\n","best_r = 100\n","\n","for i in range(config.max_epochs):\n","    print (\"Epoch: {}\".format(i))\n","\n","    train_losses,val_accuracies = run_epoch(model, train_data, val_data, tokenizer,config, optimizer)\n","    test_acc,test_r = get_metrics(model, test_x, test_y, config, tokenizer, test = True, save_path=args.test_saving_path)\n","    #print('Final Test Accuracy: {:.4f}'.format(test_acc))\n","\n","    print(\"\\tAverage training loss: {:.5f}\".format(np.mean(train_losses)))\n","    print(\"\\tAverage Val MSE: {:.4f}\".format(np.mean(val_accuracies)))\n","    if np.mean(val_accuracies) < best_val:\n","        best_val = np.mean(val_accuracies)\n","        best_test = test_acc\n","        best_r = test_r\n","        if i >= 1 and args.model_saving_path:\n","            model.save_pretrained(args.model_saving_path)\n","            tokenizer.save_pretrained(args.model_saving_path)\n","\n","\n","print('model saved at', args.model_saving_path)\n","print('best_val_loss:', best_val)\n","print('best_test_loss:',best_test)\n","print('best_test_pearsonr:',best_r)\n","\n","test_acc = get_metrics(model, test_x, test_y, config, tokenizer, test = True)\n","if args.model_saving_path:\n","    model.save_pretrained(args.model_saving_path)\n","    tokenizer.save_pretrained(args.model_saving_path)\n","\n","\n"],"metadata":{"id":"Rtx2U0jW5icU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Get Results for val and test data set"],"metadata":{"id":"N4hafSlN2pdQ"}},{"cell_type":"code","source":["print('val:')\n","test_result, test_score = get_test_result(model, val_text, val_labels, config, tokenizer,save_path=None, ext_test = False)\n","\n","print('test:')\n","test_result, test_score = get_test_result(model, test_text, test_labels, config, tokenizer,save_path=None, ext_test = False)"],"metadata":{"id":"ugxKh0actZ82"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Print attention score visualization"],"metadata":{"id":"czCZ2vT02uWg"}},{"cell_type":"code","source":["from IPython.core.display import display, HTML\n","\n","print(\"explaining ...\")\n","def visualize_attention(input_text, layer=-1):\n","\n","    inputs = tokenizer(input_text, return_tensors='pt')\n","    # print(inputs)\n","    output = model(inputs['input_ids'].to(device), output_attentions=True)\n","    attention = output.attentions[layer]\n","    # print(attention.shape)\n","    weights = attention[0, 0, :len(input_text.split()), 0].cpu().detach().numpy()\n","    assert len(input_text.split()) == len(weights)\n","\n","    return weights\n","train_text,  train_labels = get_data(args.train_path)\n","color_arrays = []\n","texts = []\n","for txt, label in zip(train_text, train_labels):\n","    if label > 0:\n","      weights = visualize_attention(txt)\n","      texts.append(txt)\n","      color_arrays.append(weights)\n","# print(texts)\n","colorize(texts, color_arrays)\n","\n","html = open('explained.html', \"r\")\n","html_text = \"\".join(html)\n","print(html_text)\n","\n","# display()\n","display({'text/html': html_text}, raw=True)"],"metadata":{"id":"-4s6CsCbznAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HZmQdv4L5N5S"},"execution_count":null,"outputs":[]}]}